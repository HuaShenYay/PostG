{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本科毕业论文推荐算法对比实验\n",
    "\n",
    "本实验旨在对比 **传统协同过滤推荐算法 (Traditional CF)** 与 **基于主题模型的协同过滤推荐算法 (Topic-CF, 本项目中采用 BERTopic)** 的推荐效果。\n",
    "\n",
    "评价指标包括：\n",
    "- **平均绝对误差 (MAE)**：衡量预测评分与实际评分的差异。值越小表示预测越准确。\n",
    "- **准确率 (Precision)**、**召回率 (Recall)**、**F1-Score**：衡量 Top-N 推荐列表的准确程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 设置中文字体，防止 matplotlib 乱码\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 导入后端 Flask 应用的上下文，以便读取数据库\n",
    "sys.path.append(os.path.abspath('../backend'))\n",
    "from app import app\n",
    "from models import db, User, Poem, Review\n",
    "from recommendation_update import IncrementalRecommender\n",
    "from bertopic_analysis import load_bertopic_model, get_document_vector\n",
    "\n",
    "print(\"环境加载成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据加载与预处理\n",
    "从系统中读取所有的用户评论和打分数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with app.app_context():\n",
    "        reviews = Review.query.all()\n",
    "        data = []\n",
    "        for r in reviews:\n",
    "            # 默认如果没有rating则为3\n",
    "            rating = r.rating if r.rating is not None else 3.0\n",
    "            # 如果有liked点赞，稍微提高分值作为隐式反馈，更贴近实际喜爱偏好\n",
    "            if r.liked:\n",
    "                rating = min(5.0, rating + 1.0)\n",
    "            data.append({\n",
    "                'user_id': r.user_id,\n",
    "                'poem_id': r.poem_id,\n",
    "                'rating': rating\n",
    "            })\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # 过滤掉交互极少(小于2次)的用户，防止冷启动问题严重污染实验数据\n",
    "        if len(df) > 0:\n",
    "            user_counts = df['user_id'].value_counts()\n",
    "            df = df[df['user_id'].isin(user_counts[user_counts >= 2].index)]\n",
    "        \n",
    "        return df\n",
    "\n",
    "df = load_data()\n",
    "print(f\"加载了 {len(df)} 条有效交互数据\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 划分训练集和测试集 (80% / 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df) > 0:\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    print(f\"训练集大小: {len(train_df)}, 测试集大小: {len(test_df)}\")\n",
    "else:\n",
    "    print(\"没有足够的数据进行切分\")\n",
    "    train_df, test_df = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "# 转换为字典格式方便查询\n",
    "train_data = defaultdict(dict)\n",
    "for _, row in train_df.iterrows():\n",
    "    train_data[int(row['user_id'])][int(row['poem_id'])] = float(row['rating'])\n",
    "    \n",
    "test_data = defaultdict(dict)\n",
    "for _, row in test_df.iterrows():\n",
    "    test_data[int(row['user_id'])][int(row['poem_id'])] = float(row['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 传统协同过滤 (User-CF)\n",
    "仅利用用户历史评分计算用户相似度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_cf_predict(u, i, k=10):\n",
    "    \"\"\"预测用户 u 对物品 i 的评分 (传统 User-CF)\"\"\"\n",
    "    # 计算当前用户的历史平均分\n",
    "    u_mean = np.mean(list(train_data[u].values())) if u in train_data and train_data[u] else 3.0\n",
    "    \n",
    "    if u not in train_data:\n",
    "        return u_mean\n",
    "    \n",
    "    sim_users = []\n",
    "    for v in train_data:\n",
    "        if v == u:\n",
    "            continue\n",
    "        if i not in train_data[v]:\n",
    "            continue\n",
    "        \n",
    "        # 找共同评分的项目\n",
    "        common_items = set(train_data[u].keys()).intersection(set(train_data[v].keys()))\n",
    "        if not common_items:\n",
    "            continue\n",
    "        \n",
    "        # 采用余弦相似度计算共同评分的相关性\n",
    "        u_ratings = [train_data[u][item] for item in common_items]\n",
    "        v_ratings = [train_data[v][item] for item in common_items]\n",
    "        if sum(u_ratings) == 0 or sum(v_ratings) == 0:\n",
    "            sim = 0\n",
    "        else:\n",
    "            sim = cosine_similarity([u_ratings], [v_ratings])[0][0]\n",
    "        sim_users.append((v, sim))\n",
    "        \n",
    "    sim_users.sort(key=lambda x: x[1], reverse=True)\n",
    "    sim_users = sim_users[:k]\n",
    "    \n",
    "    if not sim_users:\n",
    "        return u_mean\n",
    "    \n",
    "    num = 0\n",
    "    den = 0\n",
    "    for v, sim in sim_users:\n",
    "        if sim <= 0: continue\n",
    "        v_mean = np.mean(list(train_data[v].values()))\n",
    "        num += sim * (train_data[v][i] - v_mean)\n",
    "        den += sim\n",
    "        \n",
    "    if den == 0:\n",
    "        return u_mean\n",
    "    \n",
    "    pred = u_mean + num / den\n",
    "    # 截断到 1-5 之间\n",
    "    return max(1.0, min(5.0, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 基于主题模型的协同过滤 (Topic-CF / BERTopic-CF)\n",
    "利用提取的诗歌主题向量表示，计算用户画像向量，并在主题空间计算用户相似度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化现有系统中的 IncrementalRecommender，获取已有向量矩阵\n",
    "recommender = IncrementalRecommender()\n",
    "with app.app_context():\n",
    "    recommender._build_poem_vector_matrix()\n",
    "    \n",
    "def get_user_topic_vector(user_id):\n",
    "    \"\"\"利用训练集数据构建用户主题向量 (同论文中的情感/偏好向量构建)\"\"\"\n",
    "    if recommender.topic_matrix is None:\n",
    "        return None\n",
    "        \n",
    "    history = train_data.get(user_id, {})\n",
    "    if not history:\n",
    "        return None\n",
    "        \n",
    "    user_vector = np.zeros(recommender.topic_matrix.shape[1])\n",
    "    weight_sum = 0.0\n",
    "    \n",
    "    for poem_id, rating in history.items():\n",
    "        poem_idx = recommender.poem_id_map.get(poem_id)\n",
    "        if poem_idx is None:\n",
    "            continue\n",
    "            \n",
    "        rating_weight = max(0.2, min(1.0, rating / 5.0))\n",
    "        user_vector += recommender.topic_matrix[poem_idx] * rating_weight\n",
    "        weight_sum += rating_weight\n",
    "        \n",
    "    if weight_sum > 0:\n",
    "        user_vector /= weight_sum\n",
    "    return user_vector\n",
    "\n",
    "# 预计算所有用户的主题向量\n",
    "user_topic_vectors = {}\n",
    "for u in train_data.keys():\n",
    "    vec = get_user_topic_vector(u)\n",
    "    if vec is not None:\n",
    "        user_topic_vectors[u] = vec\n",
    "\n",
    "def topic_cf_predict(u, i, k=10):\n",
    "    \"\"\"预测用户 u 对物品 i 的评分 (基于主题空间的相似度)\"\"\"\n",
    "    u_mean = np.mean(list(train_data[u].values())) if u in train_data and train_data[u] else 3.0\n",
    "    \n",
    "    if u not in train_data:\n",
    "        return u_mean\n",
    "        \n",
    "    target_vec = user_topic_vectors.get(u)\n",
    "    if target_vec is None:\n",
    "        return u_mean\n",
    "        \n",
    "    sim_users = []\n",
    "    for v, v_vec in user_topic_vectors.items():\n",
    "        if v == u or v_vec is None:\n",
    "            continue\n",
    "        # 这里不需要共同评价过项目，因为是在主题向量空间直接计算用户全局相似度！\n",
    "        # 但是仍然需要用户 v 对物品 i 有评分结果，才能进行预测\n",
    "        if i not in train_data.get(v, {}):\n",
    "            continue\n",
    "            \n",
    "        if np.sum(target_vec)==0 or np.sum(v_vec)==0:\n",
    "            sim = 0\n",
    "        else:\n",
    "            sim = cosine_similarity([target_vec], [v_vec])[0][0]\n",
    "        sim_users.append((v, sim))\n",
    "        \n",
    "    sim_users.sort(key=lambda x: x[1], reverse=True)\n",
    "    sim_users = sim_users[:k]\n",
    "    \n",
    "    if not sim_users:\n",
    "        return u_mean\n",
    "        \n",
    "    num = 0\n",
    "    den = 0\n",
    "    for v, sim in sim_users:\n",
    "        if sim <= 0: continue\n",
    "        v_mean = np.mean(list(train_data[v].values()))\n",
    "        num += sim * (train_data[v][i] - v_mean)\n",
    "        den += sim\n",
    "        \n",
    "    if den == 0:\n",
    "        return u_mean\n",
    "        \n",
    "    pred = u_mean + num / den\n",
    "    return max(1.0, min(5.0, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 评价指标计算\n",
    "针对测试集进行预测，计算总体 MAE，并模拟 Top-20 推荐计算 P/R/F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mae():\n",
    "    cf_errors = []\n",
    "    topic_cf_errors = []\n",
    "    \n",
    "    for u in test_data:\n",
    "        for i, real_score in test_data[u].items():\n",
    "            # 传统CF\n",
    "            cf_pred = user_cf_predict(u, i)\n",
    "            cf_errors.append(abs(cf_pred - real_score))\n",
    "            \n",
    "            # 主题CF\n",
    "            topic_pred = topic_cf_predict(u, i)\n",
    "            topic_cf_errors.append(abs(topic_pred - real_score))\n",
    "            \n",
    "    cf_mae = np.mean(cf_errors) if cf_errors else 0\n",
    "    topic_mae = np.mean(topic_cf_errors) if topic_cf_errors else 0\n",
    "    return cf_mae, topic_mae\n",
    "\n",
    "def evaluate_top_n(N=20):\n",
    "    cf_hits, cf_rec_count, cf_real_count = 0, 0, 0\n",
    "    topic_hits, topic_rec_count, topic_real_count = 0, 0, 0\n",
    "    \n",
    "    all_items = list({item for user in train_data for item in train_data[user]})\n",
    "    \n",
    "    # 采样评估测试集中的用户\n",
    "    sample_users = list(test_data.keys())\n",
    "    \n",
    "    for u in sample_users:\n",
    "        real_positive_items = {i for i, r in test_data[u].items() if r >= 3.0}\n",
    "        if not real_positive_items:\n",
    "            continue\n",
    "            \n",
    "        cf_real_count += len(real_positive_items)\n",
    "        topic_real_count += len(real_positive_items)\n",
    "        \n",
    "        # 只针对用户没有见过的项目进行推荐\n",
    "        unseen_items = [i for i in all_items if i not in train_data.get(u, {})]\n",
    "        \n",
    "        # 为每个项目打分 \n",
    "        cf_scores = {i: user_cf_predict(u, i) for i in unseen_items}\n",
    "        topic_scores = {i: topic_cf_predict(u, i) for i in unseen_items}\n",
    "        \n",
    "        # 截取Top N\n",
    "        cf_top_n = [item[0] for item in sorted(cf_scores.items(), key=lambda x:x[1], reverse=True)[:N]]\n",
    "        topic_top_n = [item[0] for item in sorted(topic_scores.items(), key=lambda x:x[1], reverse=True)[:N]]\n",
    "        \n",
    "        cf_rec_count += N\n",
    "        topic_rec_count += N\n",
    "        \n",
    "        cf_hits += len(set(cf_top_n).intersection(real_positive_items))\n",
    "        topic_hits += len(set(topic_top_n).intersection(real_positive_items))\n",
    "        \n",
    "    def calc_metrics(hits, rec, real):\n",
    "        if rec == 0 or real == 0:\n",
    "            return 0, 0, 0\n",
    "        p = hits / rec\n",
    "        r = hits / real\n",
    "        f1 = (2 * p * r) / (p + r) if (p + r) > 0 else 0\n",
    "        return p, r, f1\n",
    "        \n",
    "    cf_p, cf_r, cf_f1 = calc_metrics(cf_hits, cf_rec_count, cf_real_count)\n",
    "    topic_p, topic_r, topic_f1 = calc_metrics(topic_hits, topic_rec_count, topic_real_count)\n",
    "    \n",
    "    return (cf_p, cf_r, cf_f1), (topic_p, topic_r, topic_f1)\n",
    "\n",
    "print(\"开始计算 MAE...\")\n",
    "cf_mae, topic_mae = evaluate_mae()\n",
    "print(\"MAE 计算完成\")\n",
    "\n",
    "print(\"开始计算 Precision, Recall, F1...\")\n",
    "cf_metrics, topic_metrics = evaluate_top_n(N=20)\n",
    "print(\"评价指标计算完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 实验结果对比与可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['Traditional CF', 'Topic-CF (Proposed)']\n",
    "mae_values = [cf_mae, topic_mae]\n",
    "precision_values = [cf_metrics[0], topic_metrics[0]]\n",
    "recall_values = [cf_metrics[1], topic_metrics[1]]\n",
    "f1_values = [cf_metrics[2], topic_metrics[2]]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('推荐算法效果对比实验结果 (Topic-CF vs Traditional CF)', fontsize=16)\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e']\n",
    "\n",
    "# 1. MAE 图 (数值越小越好)\n",
    "axs[0, 0].bar(models, mae_values, color=colors, width=0.4)\n",
    "axs[0, 0].set_title('平均绝对误差 (MAE)对比 - 越低越好')\n",
    "axs[0, 0].set_ylabel('MAE')\n",
    "for i, v in enumerate(mae_values):\n",
    "    axs[0, 0].text(i, v + 0.005, f\"{v:.4f}\", ha='center')\n",
    "\n",
    "# 2. Precision 图\n",
    "axs[0, 1].bar(models, precision_values, color=colors, width=0.4)\n",
    "axs[0, 1].set_title('准确率 (Precision)对比 - 越高越好')\n",
    "axs[0, 1].set_ylabel('Precision')\n",
    "for i, v in enumerate(precision_values):\n",
    "    axs[0, 1].text(i, v + 0.005, f\"{v:.4f}\", ha='center')\n",
    "\n",
    "# 3. Recall 图\n",
    "axs[1, 0].bar(models, recall_values, color=colors, width=0.4)\n",
    "axs[1, 0].set_title('召回率 (Recall)对比 - 越高越好')\n",
    "axs[1, 0].set_ylabel('Recall')\n",
    "for i, v in enumerate(recall_values):\n",
    "    axs[1, 0].text(i, v + 0.005, f\"{v:.4f}\", ha='center')\n",
    "\n",
    "# 4. F1-Score 图\n",
    "axs[1, 1].bar(models, f1_values, color=colors, width=0.4)\n",
    "axs[1, 1].set_title('F1得分对比 - 越高越好')\n",
    "axs[1, 1].set_ylabel('F1-Score')\n",
    "for i, v in enumerate(f1_values):\n",
    "    axs[1, 1].text(i, v + 0.005, f\"{v:.4f}\", ha='center')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"实验结果摘要：\")\n",
    "print(f\"传统 CF:\")\n",
    "print(f\"  - MAE: {cf_mae:.4f}\")\n",
    "print(f\"  - Precision: {cf_metrics[0]:.4f}\")\n",
    "print(f\"  - Recall: {cf_metrics[1]:.4f}\")\n",
    "print(f\"  - F1-Score: {cf_metrics[2]:.4f}\")\n",
    "print(f\"基于主题的 CF:\")\n",
    "print(f\"  - MAE: {topic_mae:.4f}\")\n",
    "print(f\"  - Precision: {topic_metrics[0]:.4f}\")\n",
    "print(f\"  - Recall: {topic_metrics[1]:.4f}\")\n",
    "print(f\"  - F1-Score: {topic_metrics[2]:.4f}\")\n",
    "print(\"=\"*40)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
