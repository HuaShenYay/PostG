#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨åŒ–æ¨èæ›´æ–°ç³»ç»Ÿ

åŠŸèƒ½ï¼š
1. ç›‘å¬æ•°æ®åº“å˜æ›´ï¼Œå®æ—¶æ£€æµ‹æ–°è¯—æ­Œæ’å…¥
2. æ–°è¯—æ­Œå…¥åº“å30ç§’å†…å¯åŠ¨æ¨èæ›´æ–°æµç¨‹
3. ä¸ºæ‰€æœ‰æ³¨å†Œç”¨æˆ·é‡æ–°è®¡ç®—ä¸ªæ€§åŒ–æ¨è
4. å¢é‡è®¡ç®—ä¼˜åŒ–ï¼Œå‡å°‘é‡å¤è®¡ç®—
5. å®Œå–„çš„æ—¥å¿—è®°å½•å’Œå¤±è´¥é‡è¯•æœºåˆ¶
6. æ€§èƒ½ç›‘æ§ï¼Œç¡®ä¿ç³»ç»Ÿåœ¨å¯æ¥å—æ—¶é—´å†…å®Œæˆ

ä½œè€…ï¼šè¯—äº‘å›¢é˜Ÿ
æ—¥æœŸï¼š2024
"""

import threading
import time
import json
import logging
import traceback
from datetime import datetime, timedelta
from collections import Counter
from functools import wraps
import psutil
import os

from flask import Flask, current_app
from sqlalchemy import event
from sqlalchemy.engine import Engine
from sqlalchemy.orm import Session

from config import Config
from models import db, User, Poem, Review
import pandas as pd


# ==================== é…ç½® ====================

class RecommendationConfig:
    """æ¨èç³»ç»Ÿé…ç½®"""
    
    # è§¦å‘å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
    TRIGGER_DELAY = 30
    
    # æœ€å¤§å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰
    MAX_PROCESSING_TIME = 300  # 5åˆ†é’Ÿ
    
    # èµ„æºå ç”¨é˜ˆå€¼
    CPU_THRESHOLD = 80.0  # ç™¾åˆ†æ¯”
    MEMORY_THRESHOLD = 80.0  # ç™¾åˆ†æ¯”
    
    # é‡è¯•é…ç½®
    MAX_RETRIES = 3
    RETRY_DELAY = 60  # ç§’
    
    # æ‰¹å¤„ç†å¤§å°
    BATCH_SIZE = 50
    
    # æ—¥å¿—æ–‡ä»¶
    LOG_FILE = 'logs/recommendation_update.log'


# ==================== æ—¥å¿—ç³»ç»Ÿ ====================

class RecommendationLogger:
    """æ¨èæ›´æ–°æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self):
        self.log_dir = 'logs'
        self.log_file = RecommendationConfig.LOG_FILE
        
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        os.makedirs(self.log_dir, exist_ok=True)
        
        # é…ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger('Recommendation')
    
    def log_update_start(self, trigger_type, poem_id=None):
        """è®°å½•æ›´æ–°å¼€å§‹"""
        self.logger.info(f"ğŸ”„ æ¨èæ›´æ–°å¼€å§‹ - è§¦å‘ç±»å‹: {trigger_type}" + 
                        (f", è¯—æ­ŒID: {poem_id}" if poem_id else ""))
    
    def log_update_progress(self, current, total, elapsed_time):
        """è®°å½•æ›´æ–°è¿›åº¦"""
        progress = (current / total) * 100 if total > 0 else 0
        self.logger.info(f"ğŸ“Š æ›´æ–°è¿›åº¦: {current}/{total} ({progress:.1f}%), " +
                        f"è€—æ—¶: {elapsed_time:.2f}ç§’")
    
    def log_update_success(self, users_processed, poems_count, elapsed_time):
        """è®°å½•æ›´æ–°æˆåŠŸ"""
        self.logger.info(f"âœ… æ¨èæ›´æ–°æˆåŠŸ - å¤„ç†ç”¨æˆ·: {users_processed}, " +
                        f"è¯—æ­Œæ•°: {poems_count}, æ€»è€—æ—¶: {elapsed_time:.2f}ç§’")
    
    def log_update_failure(self, error, retry_count=0):
        """è®°å½•æ›´æ–°å¤±è´¥"""
        self.logger.error(f"âŒ æ¨èæ›´æ–°å¤±è´¥ - é”™è¯¯: {error}, é‡è¯•æ¬¡æ•°: {retry_count}")
        self.logger.error(f"å †æ ˆè·Ÿè¸ª: {traceback.format_exc()}")
    
    def log_performance_metrics(self, cpu_usage, memory_usage, duration):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        self.logger.info(f"ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡ - CPU: {cpu_usage:.1f}%, " +
                        f"å†…å­˜: {memory_usage:.1f}%, è€—æ—¶: {duration:.2f}ç§’")
    
    def get_recent_logs(self, hours=24):
        """è·å–æœ€è¿‘çš„æ—¥å¿—"""
        try:
            with open(self.log_file, 'r', encoding='utf-8') as f:
                logs = f.readlines()
            
            # è¿‡æ»¤æœ€è¿‘ hours å°æ—¶çš„æ—¥å¿—
            cutoff = datetime.now() - timedelta(hours=hours)
            recent_logs = []
            for log in logs:
                if ' - ' in log:
                    timestamp_str = log.split(' - ')[0]
                    try:
                        timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S,%f')
                        if timestamp >= cutoff:
                            recent_logs.append(log.strip())
                    except:
                        recent_logs.append(log.strip())
            
            return recent_logs[-100:]  # è¿”å›æœ€è¿‘100æ¡
        except:
            return []


# ==================== æ€§èƒ½ç›‘æ§ ====================

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.start_time = None
        self.cpu_samples = []
        self.memory_samples = []
    
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        self.start_time = datetime.now()
        self.cpu_samples = []
        self.memory_samples = []
    
    def sample_resources(self):
        """é‡‡æ ·èµ„æºä½¿ç”¨"""
        try:
            process = psutil.Process(os.getpid())
            cpu = process.cpu_percent()
            memory = process.memory_percent()
            
            self.cpu_samples.append(cpu)
            self.memory_samples.append(memory)
            
            return cpu, memory
        except:
            return 0, 0
    
    def get_final_metrics(self):
        """è·å–æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡"""
        if not self.start_time:
            return 0, 0, 0
        
        duration = (datetime.now() - self.start_time).total_seconds()
        
        avg_cpu = sum(self.cpu_samples) / len(self.cpu_samples) if self.cpu_samples else 0
        avg_memory = sum(self.memory_samples) / len(self.memory_samples) if self.memory_samples else 0
        
        return avg_cpu, avg_memory, duration
    
    def check_thresholds(self):
        """æ£€æŸ¥æ˜¯å¦è¶…å‡ºé˜ˆå€¼"""
        avg_cpu, avg_memory, _ = self.get_final_metrics()
        
        return {
            'cpu_exceeded': avg_cpu > RecommendationConfig.CPU_THRESHOLD,
            'memory_exceeded': avg_memory > RecommendationConfig.MEMORY_THRESHOLD,
            'cpu_usage': avg_cpu,
            'memory_usage': avg_memory
        }


# ==================== å¢é‡æ¨èè®¡ç®— ====================

# ==================== å¢é‡æ¨èè®¡ç®— ====================
from bertopic_analysis import load_bertopic_model, predict_topic

# ==================== å¢é‡æ¨èè®¡ç®— ====================
from bertopic_analysis import load_bertopic_model, predict_topic, get_document_vector, batch_get_vectors
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

class IncrementalRecommender:
    """åŸºäºä¸»é¢˜å‘é‡çš„ååŒè¿‡æ»¤æ¨èå™¨ (Topic Vector CF)"""
    
    def __init__(self):
        self.logger = RecommendationLogger()
        self.monitor = PerformanceMonitor()
        self.bertopic_model = load_bertopic_model()
        self.topic_matrix = None # è¯—æ­Œä¸»é¢˜å‘é‡çŸ©é˜µ (n_poems, vector_dim)
        self.poem_id_map = {}    # poem_id -> matrix_index
        self.poem_ids = []       # [poem_id1, poem_id2, ...]
        
        self.cache_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'saved_models', 'vector_cache')
        os.makedirs(self.cache_dir, exist_ok=True)
        
        # é¢„åŠ è½½å‘é‡çŸ©é˜µ
        self._build_poem_vector_matrix()

    def update_user_preference(self, user_id):
        """åˆ†æç”¨æˆ·æ‰€æœ‰è¯„è®ºï¼Œæ›´æ–°ç”¨æˆ·åå¥½ä¸»é¢˜æ–‡æœ¬ (Restored from previous version)"""
        reviews = Review.query.filter_by(user_id=user_id).all()
        if not reviews:
            return ""
        
        # ç»Ÿè®¡ç”¨æˆ·è¯„è®ºä¸­å‡ºç°çš„ä¸»é¢˜åé¢‘ç‡
        topic_counts = Counter()
        for r in reviews:
            if r.topic_names:
                names = r.topic_names.split(',')
                topic_counts.update(names)
        
        if not topic_counts:
            return ""
        
        # è·å–æœ€åŒ¹é…çš„Top 3ä¸»é¢˜ä½œä¸ºåå¥½æè¿°
        top_topics = [t for t, _ in topic_counts.most_common(3)]
        return ",".join(top_topics)
    
    def _build_poem_vector_matrix(self):
        """æ„å»ºå…¨é‡è¯—æ­Œå‘é‡çŸ©é˜µï¼ˆæ”¯æŒç¼“å­˜åŠ è½½ï¼‰"""
        if not self.bertopic_model:
            return
            
        with current_app.app_context():
            poems = Poem.query.all()
            if not poems:
                return
            
            self.poem_ids = [p.id for p in poems]
            self.poem_id_map = {pid: idx for idx, pid in enumerate(self.poem_ids)}
            
            # å°è¯•ä»ç¼“å­˜åŠ è½½
            matrix_path = os.path.join(self.cache_dir, 'topic_matrix.npy')
            ids_path = os.path.join(self.cache_dir, 'poem_ids.json')
            
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ (IDåˆ—è¡¨åŒ¹é…)
            cache_valid = False
            if os.path.exists(matrix_path) and os.path.exists(ids_path):
                try:
                    with open(ids_path, 'r') as f:
                        cached_ids = json.load(f)
                    if cached_ids == self.poem_ids:
                        self.topic_matrix = np.load(matrix_path)
                        self.logger.logger.info(f"æˆåŠŸä»ç¼“å­˜åŠ è½½ {len(self.poem_ids)} é¦–è¯—æ­Œçš„å‘é‡çŸ©é˜µ")
                        cache_valid = True
                except Exception as e:
                    self.logger.logger.warning(f"ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
            
            if not cache_valid:
                # è·å–æ‰€æœ‰è¯—æ­Œå†…å®¹é‡æ–°è®¡ç®—
                contents = [p.content for p in poems]
                self.logger.logger.info(f"æ­£åœ¨æ„å»º {len(poems)} é¦–è¯—æ­Œçš„å‘é‡çŸ©é˜µ (å…¨é‡è®¡ç®—)...")
                self.topic_matrix = batch_get_vectors(contents, self.bertopic_model)
                
                # ä¿å­˜åˆ°ç¼“å­˜
                try:
                    np.save(matrix_path, self.topic_matrix)
                    with open(ids_path, 'w') as f:
                        json.dump(self.poem_ids, f)
                    self.logger.logger.info("å‘é‡çŸ©é˜µå·²æŒä¹…åŒ–åˆ°æœ¬åœ°ç¼“å­˜")
                except Exception as e:
                    self.logger.logger.error(f"ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
            
            self.logger.logger.info("å‘é‡çŸ©é˜µå‡†å¤‡å°±ç»ª")

    def _get_user_profile_vector(self, user_id):
        """æ„å»ºç”¨æˆ·åå¥½å‘é‡ (åŸºäºäº¤äº’å†å²åŠ æƒå¹³å‡)"""
        reviews = Review.query.filter_by(user_id=user_id).all()
        if not reviews or self.topic_matrix is None:
            return None
            
        user_vector = np.zeros(self.topic_matrix.shape[1])
        weight_sum = 0
        
        for r in reviews:
            poem_idx = self.poem_id_map.get(r.poem_id)
            if poem_idx is not None:
                # ç®€å•æƒé‡: 1.0 (æœªæ¥å¯ä»¥å¼•å…¥è¯„åˆ†ç³»ç»Ÿ)
                w = 1.0
                user_vector += self.topic_matrix[poem_idx] * w
                weight_sum += w
                
        if weight_sum > 0:
            user_vector /= weight_sum
            
        return user_vector

    def _get_similar_users(self, target_user_id, top_k=10):
        """å¯»æ‰¾ç›¸ä¼¼ç”¨æˆ· (User-CF Strategy)"""
        target_vector = self._get_user_profile_vector(target_user_id)
        if target_vector is None:
            return []
            
        # è·å–æ‰€æœ‰æ´»è·ƒç”¨æˆ·çš„å‘é‡
        other_users = User.query.filter(User.id != target_user_id, User.total_reviews > 0).limit(100).all() # é™åˆ¶è®¡ç®—é‡
        similarities = []
        
        for u in other_users:
            u_vector = self._get_user_profile_vector(u.id)
            if u_vector is not None:
                sim = cosine_similarity([target_vector], [u_vector])[0][0]
                similarities.append((u.id, sim))
        
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:top_k]

    def _topic_based_item_cf(self, user_reviewed_ids, all_poem_indices, top_n=20):
        """åŸºäºç‰©å“çš„ä¸»é¢˜ååŒè¿‡æ»¤"""
        if not user_reviewed_ids or self.topic_matrix is None:
            return []
            
        # è·å–ç”¨æˆ·å–œæ¬¢çš„è¯—æ­Œçš„å‘é‡
        user_reviewed_indices = [self.poem_id_map[pid] for pid in user_reviewed_ids if pid in self.poem_id_map]
        if not user_reviewed_indices:
            return []
            
        reviewed_vectors = self.topic_matrix[user_reviewed_indices]
        
        # è®¡ç®—æ‰€æœ‰è¯—æ­Œä¸ç”¨æˆ·å†å²è¯—æ­Œçš„ç›¸ä¼¼åº¦å¹³å‡å€¼
        # è¿™é‡Œä½¿ç”¨çŸ©é˜µè¿ç®—åŠ é€Ÿ: (n_all, dim) . (n_reviewed, dim).T -> (n_all, n_reviewed)
        sim_matrix = cosine_similarity(self.topic_matrix, reviewed_vectors)
        # å–å¹³å‡ç›¸ä¼¼åº¦ä½œä¸ºå¾—åˆ†
        scores = np.mean(sim_matrix, axis=1)
        
        # æ’é™¤å·²è¯»
        for idx in user_reviewed_indices:
            scores[idx] = -1.0
            
        # è·å–Top-N
        top_indices = np.argsort(scores)[::-1][:top_n]
        return [(self.poem_ids[i], float(scores[i])) for i in top_indices if scores[i] > 0]

    def _content_based_recommend(self, target_vector, user_reviewed_indices, top_n=20):
        """åŸºäºç”¨æˆ·ç”»åƒå‘é‡çš„å†…å®¹æ¨è"""
        if self.topic_matrix is None or target_vector is None:
            return []
            
        # è®¡ç®—ç”¨æˆ·å‘é‡ä¸æ‰€æœ‰è¯—æ­Œçš„ç›¸ä¼¼åº¦
        scores = cosine_similarity([target_vector], self.topic_matrix)[0]
        
        # æ’é™¤å·²è¯»
        for idx in user_reviewed_indices:
            scores[idx] = -1.0
            
        top_indices = np.argsort(scores)[::-1][:top_n]
        return [(self.poem_ids[i], float(scores[i])) for i in top_indices if scores[i] > 0]

    def get_new_poems_for_user(self, user_id, limit=6):
        """æ··åˆæ¨èä¸»é€»è¾‘ (Hybrid Strategy)"""
        user = User.query.get(user_id)
        if not user or not self.bertopic_model:
            return self.get_global_popular(limit)
        
        if self.topic_matrix is None:
            self._build_poem_vector_matrix()
            
        user_reviews = Review.query.filter_by(user_id=user_id).all()
        user_reviewed_ids = {r.poem_id for r in user_reviews}
        user_reviewed_indices = [self.poem_id_map[pid] for pid in user_reviewed_ids if pid in self.poem_id_map]
        
        interaction_count = len(user_reviews)
        candidates = {} # poem_id -> total_score
        
        # å®šä¹‰åŠ¨æ€æƒé‡
        if interaction_count == 0:
            # å†·å¯åŠ¨ç”¨æˆ·: çƒ­é—¨ä¸ºä¸»
            w_cf_user = 0.0
            w_cf_item = 0.0
            w_content = 0.4
            w_popular = 0.6
        elif interaction_count < 10:
            # è½»åº¦ç”¨æˆ·: å†…å®¹+ItemCFä¸ºä¸»
            w_cf_user = 0.2
            w_cf_item = 0.4
            w_content = 0.3
            w_popular = 0.1
        else:
            # é‡åº¦ç”¨æˆ·: ååŒè¿‡æ»¤ä¸ºä¸»
            w_cf_user = 0.4
            w_cf_item = 0.4
            w_content = 0.2
            w_popular = 0.0
            
        # 1. User-CF Strategy (ç®€åŒ–ç‰ˆ: åªå–ç›¸ä¼¼ç”¨æˆ·æœ€è¿‘å–œæ¬¢çš„ä¸€é¦–)
        if w_cf_user > 0:
            similar_users = self._get_similar_users(user_id)
            for sim_uid, sim_score in similar_users:
                sim_reviews = Review.query.filter_by(user_id=sim_uid).order_by(Review.created_at.desc()).limit(5).all()
                for r in sim_reviews:
                    if r.poem_id not in user_reviewed_ids:
                        candidates[r.poem_id] = candidates.get(r.poem_id, 0) + (sim_score * w_cf_user)

        # 2. Item-CF Strategy
        if w_cf_item > 0:
            item_recs = self._topic_based_item_cf(user_reviewed_ids, None)
            for pid, score in item_recs:
                candidates[pid] = candidates.get(pid, 0) + (score * w_cf_item)
                
        # 3. Content-Based Strategy
        if w_content > 0:
            user_vec = self._get_user_profile_vector(user_id)
            if user_vec is not None:
                content_recs = self._content_based_recommend(user_vec, user_reviewed_indices)
                for pid, score in content_recs:
                    candidates[pid] = candidates.get(pid, 0) + (score * w_content)
                    
        # 4. Popularity Strategy (Fallback)
        if w_popular > 0 or not candidates:
            popular_poems = self.get_global_popular(limit * 2)
            for p in popular_poems:
                if p.id not in user_reviewed_ids:
                    # å½’ä¸€åŒ–: çƒ­é—¨åˆ† 0~1
                    pop_score = min(p.views / 1000.0, 1.0)
                    candidates[p.id] = candidates.get(p.id, 0) + (pop_score * w_popular)
        
        # æ’åºä¸è¿”å›
        sorted_ids = sorted(candidates.keys(), key=lambda k: candidates[k], reverse=True)
        final_ids = sorted_ids[:limit]
        
        # å…œåº•
        if len(final_ids) < limit:
            remaining = limit - len(final_ids)
            pops = self.get_global_popular(remaining + 20) # å¤šå–ç‚¹é˜²é‡é‡å¤
            for p in pops:
                if p.id not in user_reviewed_ids and p.id not in final_ids:
                    final_ids.append(p.id)
                    if len(final_ids) >= limit:
                        break
                        
        # ä¿æŒé¡ºåºè¿”å›å¯¹è±¡
        id_map = {p.id: p for p in Poem.query.filter(Poem.id.in_(final_ids)).all()}
        return [id_map[pid] for pid in final_ids if pid in id_map]
    
    def get_global_popular(self, limit=6):
        """è·å–å…¨å±€çƒ­é—¨è¯—æ­Œ"""
        return Poem.query.order_by(Poem.views.desc()).limit(limit).all()
    
    def batch_update_all_recommendations(self, app=None):
        """å…¨é‡æ›´æ–°æ¨èé€»è¾‘"""
        flask_app = app or current_app
        with flask_app.app_context():
            # é‡å»ºå‘é‡çŸ©é˜µ
            self._build_poem_vector_matrix() # ç¡®ä¿æœ€æ–°
            
            # æ›´æ–°ç”¨æˆ·åå¥½ç¼“å­˜ (topics string)
            # è™½ç„¶æ–°ç®—æ³•ä¸»è¦ç”¨å‘é‡å®æ—¶è®¡ç®—ï¼Œä½†ä¸ºäº†å‰ç«¯å±•ç¤ºï¼Œæˆ‘ä»¬è¿˜æ˜¯ç»´æŠ¤ preference_topics å­—æ®µ
            users = User.query.all()
            for user in users:
                user.preference_topics = self.update_user_preference(user.id)
                user.total_reviews = Review.query.filter_by(user_id=user.id).count()
            db.session.commit()
            
            # æ›´æ–°è¯—æ­Œå…ƒæ•°æ®
            poems = Poem.query.all()
            for poem in poems:
                if not poem.LDA_topic and self.bertopic_model:
                     tid, tname = predict_topic(poem.content, self.bertopic_model)
                     poem.LDA_topic = tname
                     poem.Real_topic = str(tid)
                poem.review_count = Review.query.filter_by(poem_id=poem.id).count()
            db.session.commit()

    def batch_update_recommendations(self, user_ids=None, trigger_type='manual', poem_id=None, app=None):
        """æ‰¹é‡æ›´æ–°ç”¨æˆ·æ¨èçŠ¶æ€"""
        flask_app = app or current_app
        
        with flask_app.app_context():
            if trigger_type == 'new_poem' and poem_id:
                # å¦‚æœæ˜¯æ–°è¯—æ’å…¥ï¼Œä¸ºæ–°è¯—è®¡ç®— BERTopic ä¸»é¢˜
                poem = Poem.query.get(poem_id)
                if poem and self.bertopic_model:
                    tid, tname = predict_topic(poem.content, self.bertopic_model)
                    poem.LDA_topic = tname
                    poem.Real_topic = str(tid)
                    db.session.commit()
                    
                    # æ›´æ–°å‘é‡çŸ©é˜µç¼“å­˜ (å¢é‡æ›´æ–°æš‚æœªå®ç°ï¼Œç®€å•è§¦å‘å…¨é‡é‡å»ºæˆ–append)
                    if self.topic_matrix is not None:
                        # ç®€å•çš„å¢é‡æ·»åŠ 
                        vec = get_document_vector(poem.content, self.bertopic_model)
                        if vec is not None:
                            self.topic_matrix = np.vstack([self.topic_matrix, vec])
                            self.poem_ids.append(poem.id)
                            self.poem_id_map[poem.id] = len(self.poem_ids) - 1

            self.batch_update_all_recommendations(flask_app)
            
        return {'success': True, 'processed_users': len(user_ids) if user_ids else 0}


# ==================== æ¨èæ›´æ–°æœåŠ¡ ====================

class RecommendationUpdateService:
    """æ¨èæ›´æ–°æœåŠ¡"""
    
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
        
        self._initialized = True
        self.logger = RecommendationLogger()
        self.recommender = IncrementalRecommender()
        self.pending_update = None
        self.update_lock = threading.Lock()
        self.retry_count = 0
        self.last_update_time = None
        self.new_poem_ids = []  # å¾…å¤„ç†çš„æ–°è¯—æ­ŒIDåˆ—è¡¨
        self.last_poem_count = 0  # ä¸Šæ¬¡æ£€æµ‹çš„è¯—æ­Œæ•°é‡
        self.poll_thread = None  # åå°è½®è¯¢çº¿ç¨‹
        self.app = None  # ä¿å­˜ Flask åº”ç”¨å¼•ç”¨
    
    def register_database_listener(self, app):
        """æ³¨å†Œæ•°æ®åº“å˜æ›´ç›‘å¬å™¨ - ä½¿ç”¨åå°è½®è¯¢æœºåˆ¶"""
        self.app = app  # ä¿å­˜åº”ç”¨å¼•ç”¨
        
        with app.app_context():
            # è·å–å½“å‰è¯—æ­Œæ•°é‡ (å®¹é”™å¤„ç†)
            try:
                self.last_poem_count = Poem.query.count()
                self.logger.logger.info(f"ğŸ¯ ç›‘å¬å™¨å¯åŠ¨ï¼Œå½“å‰è¯—æ­Œæ•°: {self.last_poem_count}")
            except Exception:
                self.last_poem_count = 0
                self.logger.logger.warning("âš ï¸ ç›‘å¬å™¨å¯åŠ¨: æ•°æ®åº“è¡¨å°šä¸å¯ç”¨ï¼Œç­‰å¾…åˆå§‹åŒ–")
            
            # å¯åŠ¨åå°è½®è¯¢çº¿ç¨‹
            self.poll_thread = threading.Thread(
                target=self._poll_for_new_poems,
                args=(app,),
                daemon=True
            )
            self.poll_thread.start()
    
    def _poll_for_new_poems(self, app):
        """è½®è¯¢æ£€æµ‹æ–°è¯—æ­Œï¼ˆæ¯10ç§’æ£€æŸ¥ä¸€æ¬¡ï¼‰"""
        while True:
            try:
                time.sleep(10)  # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡
                
                with app.app_context():
                    current_count = Poem.query.count()
                    
                    if current_count > self.last_poem_count:
                        # æœ‰æ–°è¯—æ­Œ
                        new_count = current_count - self.last_poem_count
                        self.last_poem_count = current_count
                        
                        # è·å–æœ€æ–°æ’å…¥çš„è¯—æ­ŒID
                        latest_poem = Poem.query.order_by(Poem.id.desc()).first()
                        if latest_poem:
                            self.logger.logger.info(
                                f"ğŸ“ æ£€æµ‹åˆ° {new_count} é¦–æ–°è¯—æ­Œ, æœ€æ–°ID: {latest_poem.id}"
                            )
                            self._on_new_poem_inserted(latest_poem.id)
                    
            except Exception as e:
                self.logger.logger.error(f"è½®è¯¢é”™è¯¯: {e}")
                time.sleep(30)  # é”™è¯¯æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´
    
    def _on_new_poem_inserted(self, poem_id):
        """æ–°è¯—æ­Œæ’å…¥å¤„ç†"""
        with self.update_lock:
            # æ·»åŠ åˆ°å¾…å¤„ç†åˆ—è¡¨
            self.new_poem_ids.append(poem_id)
            
            # å¦‚æœå·²ç»åœ¨ç­‰å¾…æ›´æ–°ï¼Œä¸å†é‡å¤æ·»åŠ 
            if self.pending_update is not None:
                return
            
            # è®¾ç½®å»¶è¿Ÿè§¦å‘
            self.pending_update = threading.Timer(
                RecommendationConfig.TRIGGER_DELAY,
                self._trigger_update,
                args=(poem_id,)
            )
            self.pending_update.start()
            
            self.logger.logger.info(
                f"ğŸ“ æ£€æµ‹åˆ°æ–°è¯—æ­Œ (ID: {poem_id}), "
                f"å°†åœ¨ {RecommendationConfig.TRIGGER_DELAY} ç§’åè§¦å‘æ¨èæ›´æ–°"
            )
    
    def _trigger_update(self, poem_id):
        """è§¦å‘æ›´æ–°"""
        with self.update_lock:
            self.pending_update = None
            
            # å¼€å§‹æ‰¹é‡æ›´æ–°ï¼Œä¼ å…¥ app å¼•ç”¨
            result = self.recommender.batch_update_recommendations(
                user_ids=None,
                trigger_type='new_poem',
                poem_id=poem_id,
                app=self.app
            )
            
            # å¤„ç†å¤±è´¥é‡è¯•
            if not result.get('success', False):
                self._handle_retry(poem_id, result)
            else:
                self.retry_count = 0
                self.last_update_time = datetime.now()
                self.new_poem_ids = []  # æ¸…ç©ºå¾…å¤„ç†åˆ—è¡¨
    
    def _handle_retry(self, poem_id, last_result):
        """å¤„ç†å¤±è´¥é‡è¯•"""
        if self.retry_count < RecommendationConfig.MAX_RETRIES:
            self.retry_count += 1
            
            delay = RecommendationConfig.RETRY_DELAY * self.retry_count
            
            self.logger.logger.info(
                f"ğŸ”„ è®¡åˆ’é‡è¯•æ¨èæ›´æ–° (å°è¯• {self.retry_count}/{RecommendationConfig.MAX_RETRIES}), "
                f"ç­‰å¾… {delay} ç§’"
            )
            
            # å»¶è¿Ÿåé‡è¯•
            timer = threading.Timer(
                delay,
                self._trigger_update,
                args=(poem_id,)
            )
            timer.start()
        else:
            self.logger.log_update_failure(
                f"å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({RecommendationConfig.MAX_RETRIES})",
                retry_count=self.retry_count
            )
            self.retry_count = 0
    
    def manual_trigger_update(self, poem_id=None):
        """æ‰‹åŠ¨è§¦å‘æ›´æ–°"""
        if self.app is None:
            return {'success': False, 'error': 'App not initialized'}
        
        with self.app.app_context():
            user_ids = [u.id for u in User.query.all()]
        
        if not user_ids:
            return {'success': False, 'error': 'æ²¡æœ‰ç”¨æˆ·'}
        
        result = self.recommender.batch_update_recommendations(
            user_ids,
            trigger_type='manual',
            poem_id=poem_id
        )
        
        if result.get('success', False):
            self.last_update_time = datetime.now()
        
        return result
    
    def get_update_status(self):
        """è·å–æ›´æ–°çŠ¶æ€"""
        return {
            'is_updating': self.pending_update is not None,
            'pending_poems': self.new_poem_ids.copy(),
            'last_update_time': self.last_update_time.isoformat() if self.last_update_time else None,
            'retry_count': self.retry_count,
            'config': {
                'trigger_delay': RecommendationConfig.TRIGGER_DELAY,
                'max_processing_time': RecommendationConfig.MAX_PROCESSING_TIME,
                'cpu_threshold': RecommendationConfig.CPU_THRESHOLD,
                'memory_threshold': RecommendationConfig.MEMORY_THRESHOLD,
                'max_retries': RecommendationConfig.MAX_RETRIES,
                'batch_size': RecommendationConfig.BATCH_SIZE
            }
        }


# ==================== é›†æˆåˆ° Flask åº”ç”¨ ====================

recommendation_service = None

def init_recommendation_system(app):
    """åˆå§‹åŒ–æ¨èç³»ç»Ÿ"""
    global recommendation_service
    
    # åˆ›å»ºæ¨èæ›´æ–°æœåŠ¡
    recommendation_service = RecommendationUpdateService()
    
    # æ³¨å†Œæ•°æ®åº“ç›‘å¬å™¨
    recommendation_service.register_database_listener(app)
    
    # è®°å½•åˆå§‹åŒ–å®Œæˆ
    logger = RecommendationLogger()
    logger.logger.info("ğŸ¯ æ¨èæ›´æ–°ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    logger.logger.info(f"   - è§¦å‘å»¶è¿Ÿ: {RecommendationConfig.TRIGGER_DELAY}ç§’")
    logger.logger.info(f"   - æœ€å¤§å¤„ç†æ—¶é—´: {RecommendationConfig.MAX_PROCESSING_TIME}ç§’")
    logger.logger.info(f"   - CPUé˜ˆå€¼: {RecommendationConfig.CPU_THRESHOLD}%")
    logger.logger.info(f"   - å†…å­˜é˜ˆå€¼: {RecommendationConfig.MEMORY_THRESHOLD}%")
    logger.logger.info(f"   - æœ€å¤§é‡è¯•æ¬¡æ•°: {RecommendationConfig.MAX_RETRIES}")


def add_recommendation_routes(app):
    """æ·»åŠ æ¨èç³»ç»Ÿç›¸å…³çš„ API è·¯ç”±"""
    
    @app.route('/api/admin/recommendation/status')
    def get_recommendation_status():
        """è·å–æ¨èç³»ç»ŸçŠ¶æ€"""
        if recommendation_service is None:
            return jsonify({'error': 'æ¨èç³»ç»Ÿæœªåˆå§‹åŒ–'}), 500
        
        return jsonify(recommendation_service.get_update_status())
    
    @app.route('/api/admin/recommendation/trigger', methods=['POST'])
    def trigger_recommendation_update():
        """æ‰‹åŠ¨è§¦å‘æ¨èæ›´æ–°"""
        if recommendation_service is None:
            return jsonify({'error': 'æ¨èç³»ç»Ÿæœªåˆå§‹åŒ–'}), 500
        
        data = request.json or {}
        poem_id = data.get('poem_id')
        
        result = recommendation_service.manual_trigger_update(poem_id)
        
        if result.get('success', False):
            return jsonify({
                'message': 'æ¨èæ›´æ–°å®Œæˆ',
                'details': result
            })
        else:
            return jsonify({
                'message': 'æ¨èæ›´æ–°å¤±è´¥',
                'error': result.get('error'),
                'details': result
            }), 500
    
    @app.route('/api/admin/recommendation/logs')
    def get_recommendation_logs():
        """è·å–æ¨èæ›´æ–°æ—¥å¿—"""
        logger = RecommendationLogger()
        hours = request.args.get('hours', 24, type=int)
        logs = logger.get_recent_logs(hours)
        return jsonify(logs)


# ==================== å•ç‹¬è¿è¡Œæµ‹è¯• ====================

if __name__ == '__main__':
    print("=" * 60)
    print("è‡ªåŠ¨åŒ–æ¨èæ›´æ–°ç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)
    print()
    
    # æ¨¡æ‹Ÿæµ‹è¯•
    print("1. æµ‹è¯•é…ç½®åŠ è½½...")
    print(f"   è§¦å‘å»¶è¿Ÿ: {RecommendationConfig.TRIGGER_DELAY}ç§’")
    print(f"   æœ€å¤§å¤„ç†æ—¶é—´: {RecommendationConfig.MAX_PROCESSING_TIME}ç§’")
    print(f"   CPUé˜ˆå€¼: {RecommendationConfig.CPU_THRESHOLD}%")
    print(f"   å†…å­˜é˜ˆå€¼: {RecommendationConfig.MEMORY_THRESHOLD}%")
    print(f"   æœ€å¤§é‡è¯•æ¬¡æ•°: {RecommendationConfig.MAX_RETRIES}")
    print()
    
    print("2. æµ‹è¯•æ—¥å¿—ç³»ç»Ÿ...")
    test_logger = RecommendationLogger()
    test_logger.logger.info("æµ‹è¯•æ—¥å¿—è®°å½•")
    print("   âœ“ æ—¥å¿—è®°å½•æˆåŠŸ")
    print()
    
    print("3. æµ‹è¯•æ€§èƒ½ç›‘æ§...")
    monitor = PerformanceMonitor()
    monitor.start_monitoring()
    time.sleep(0.5)
    cpu, memory = monitor.sample_resources()
    avg_cpu, avg_memory, duration = monitor.get_final_metrics()
    print(f"   CPUä½¿ç”¨ç‡: {avg_cpu:.1f}%")
    print(f"   å†…å­˜ä½¿ç”¨ç‡: {avg_memory:.1f}%")
    print(f"   ç›‘æ§æ—¶é•¿: {duration:.2f}ç§’")
    print()
    
    print("4. æµ‹è¯•å¢é‡æ¨èè®¡ç®—...")
    recommender = IncrementalRecommender()
    print("   âœ“ æ¨èè®¡ç®—å™¨åˆå§‹åŒ–æˆåŠŸ")
    print()
    
    print("=" * 60)
    print("æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)
